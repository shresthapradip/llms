{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1daf9bc8-ac1f-4402-b4cc-69f02b468c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::020571837677:role/NIAID-SageMakeFullAccess\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # boto_session = boto3.Session(profile_name='ocicb-sandbox-alpha-dev-admin')\n",
    "    # sess = sagemaker.Session(boto_session=boto_session)\n",
    "    # role = sagemaker.get_execution_role()\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='NIAID-SageMakeFullAccess')['Role']['Arn']\n",
    "    print(role)\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='NIAID-SageMakeFullAccess')['Role']['Arn']\n",
    "\n",
    "def deploy_bart_large_cnn():\n",
    "    \n",
    "    # bart-large-cnn\n",
    "    # Hub Model configuration. https://huggingface.co/models\n",
    "    hub = {\n",
    "    \t'HF_MODEL_ID':'facebook/bart-large-cnn',\n",
    "    \t'HF_TASK':'summarization'\n",
    "    }\n",
    "    \n",
    "    # create Hugging Face Model Class\n",
    "    huggingface_model = HuggingFaceModel(\n",
    "    \ttransformers_version='4.37.0',\n",
    "    \tpytorch_version='2.1.0',\n",
    "    \tpy_version='py310',\n",
    "    \tenv=hub,\n",
    "    \trole=role, \n",
    "    )\n",
    "\n",
    "    # deploy model to SageMaker Inference\n",
    "    predictor = huggingface_model.deploy(\n",
    "    \tinitial_instance_count=1, # number of instances\n",
    "    \tinstance_type='ml.m5.xlarge' # ec2 instance type\n",
    "    )\n",
    "    return predictor\n",
    "\n",
    "def deploy_t5():\n",
    "    # Hub Model configuration. https://huggingface.co/models\n",
    "    hub = {\n",
    "    \t'HF_MODEL_ID':'google-t5/t5-base',\n",
    "    \t'SM_NUM_GPUS': json.dumps(1)\n",
    "    }\n",
    "    # create Hugging Face Model Class\n",
    "    huggingface_model = HuggingFaceModel(\n",
    "    \ttransformers_version='4.37.0',\n",
    "    \tpytorch_version='2.1.0',\n",
    "    \tpy_version='py310',\n",
    "    \tenv=hub,\n",
    "    \trole=role, \n",
    "    )\n",
    "    \n",
    "    # deploy model to SageMaker Inference\n",
    "    predictor = huggingface_model.deploy(\n",
    "    \tinitial_instance_count=1,\n",
    "    \tinstance_type=\"ml.g5.2xlarge\",\n",
    "    \tcontainer_startup_health_check_timeout=300,\n",
    "      )\n",
    "    return predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "532ed507-f392-4bfb-b2e2-3c908ac537df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = deploy_t5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fee8e590-b948-45bd-b01e-72813360d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFacePredictor: {'endpoint_name': 'huggingface-pytorch-inference-2024-07-29-18-29-03-005', 'sagemaker_session': <sagemaker.session.Session object at 0x2e570b650>, 'serializer': <sagemaker.base_serializers.JSONSerializer object at 0x2975e4a10>, 'deserializer': <sagemaker.base_deserializers.JSONDeserializer object at 0x2975e4bd0>}\n"
     ]
    }
   ],
   "source": [
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc4aa721-9ada-46a6-ba12-4fd958a7e507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.huggingface.model.HuggingFaceModel object at 0x29c8a0f50>\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface.model import HuggingFacePredictor, HuggingFaceModel\n",
    "\n",
    "endpoint_name = \"huggingface-pytorch-inference-2024-07-29-18-29-03-005\"\n",
    "predictor = HuggingFacePredictor(endpoint_name)\n",
    "model = HuggingFaceModel(endpoint_name, py_version='py310', transformers_version='4.37.0', pytorch_version='2.1.0',)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "871b3617-da71-44c6-952e-32a69eac6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = predictor.predict({\n",
    "\t\"inputs\": \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d0fda7f-5e0c-4117-bffa-d4510d83b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tallest structure in Paris., it is the tallest structure in Paris\n"
     ]
    }
   ],
   "source": [
    "print(summary[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "534e484f-8d01-4fa5-b100-efb8b2b1b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aiayn.pdf\n",
      "39593\n",
      "[{'generated_text': 'USA is great country. USA has diverse population.'}]\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "import fitz\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import textwrap\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Preprocess text for T5\n",
    "    input_text = \"summarize: USA is great country. USA has diverse population. USA has 50 states.\"\n",
    "    # Generate summary\n",
    "    summary_ids = predictor.predict({\"inputs\": input_text})\n",
    "    print(summary_ids)\n",
    "    \n",
    "    \n",
    "def summarize_pdf(file):\n",
    "    print(file)\n",
    "    doc = pymupdf.fitz(file)  # Open the PDF file\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)  \n",
    "        text += page.get_text()  \n",
    "    print(len(text))\n",
    "    return summarize_text(text)\n",
    "\n",
    "summarize_pdf('./data/aiayn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6afc19b2-3f17-4950-9b9b-162804621be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/var/folders/tk/s70x7yfs2891bdbmc0zg65qx_b4w3m/T/gradio/53ad2a6f1a2ec53d745dbc4350fa1247d6f79972/NIAID_DAR-1718658969.1616802.pdf\n",
      "2661\n",
      "tensor([[21603,    10,     8,  5065,   222,  1809,    16,  1919,     5,     6,\n",
      "            34,    19,     8,  5065,   222,  1809,    16,  1919,     1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/gradio/queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/gradio/route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1923, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1508, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shresthap/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/gradio/utils.py\", line 818, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/tk/s70x7yfs2891bdbmc0zg65qx_b4w3m/T/ipykernel_42031/849343199.py\", line 24, in summarize_pdf\n",
      "    return summarize_text(summary[0]['generated_text'])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/tk/s70x7yfs2891bdbmc0zg65qx_b4w3m/T/ipykernel_42031/849343199.py\", line 11, in summarize_text\n",
      "    summary_ids = model.generate(inputs)\n",
      "                  ^^^^^^^^^^^^^^\n",
      "AttributeError: 'HuggingFaceModel' object has no attribute 'generate'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "# Create the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=summarize_pdf,\n",
    "    inputs=gr.File(file_count=\"single\", type=\"filepath\", label=\"Upload PDF File\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"PDF File Summarizer\",\n",
    "    description=\"Upload a single PDF file to summarize.\"\n",
    ")\n",
    "\n",
    "interface.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f7441-dc74-4a1a-b2b3-8f11ada7ec41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e564c3e-7d9e-41fc-b1f6-8f3cda3a66ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed2ca6b9-dc6e-43c9-b796-45d1f528c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ded9f4e7-0043-460b-bfee-07c098c8a7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.accumulate at 0x2aedfb600>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "itertools.accumulate(itertools.cycle(map(ord, \"Close\")), initial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08ea23b4-81c9-4456-b907-d0315ec0238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_content\n\u001b[1;32m     35\u001b[0m urls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.wsj.com\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 36\u001b[0m extracted_content \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_with_playwright\u001b[49m\u001b[43m(\u001b[49m\u001b[43murls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 16\u001b[0m, in \u001b[0;36mscrape_with_playwright\u001b[0;34m(urls, schema)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_with_playwright\u001b[39m(urls, schema):\n\u001b[1;32m     15\u001b[0m     loader \u001b[38;5;241m=\u001b[39m AsyncChromiumLoader(urls)\n\u001b[0;32m---> 16\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     bs_transformer \u001b[38;5;241m=\u001b[39m BeautifulSoupTransformer()\n\u001b[1;32m     18\u001b[0m     docs_transformed \u001b[38;5;241m=\u001b[39m bs_transformer\u001b[38;5;241m.\u001b[39mtransform_documents(\n\u001b[1;32m     19\u001b[0m         docs, tags_to_extract\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/langchain_core/document_loaders/base.py:30\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/rag/llama-langchain/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/chromium.py:85\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mLazily load text content from the provided URLs.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murls:\n\u001b[0;32m---> 85\u001b[0m     html_content \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascrape_playwright\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: url}\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m Document(page_content\u001b[38;5;241m=\u001b[39mhtml_content, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "from langchain_community.document_loaders import AsyncChromiumLoader\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"news_article_title\": {\"type\": \"string\"},\n",
    "        \"news_article_summary\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"news_article_title\", \"news_article_summary\"],\n",
    "}\n",
    "def scrape_with_playwright(urls, schema):\n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "    bs_transformer = BeautifulSoupTransformer()\n",
    "    docs_transformed = bs_transformer.transform_documents(\n",
    "        docs, tags_to_extract=[\"span\"]\n",
    "    )\n",
    "    print(\"Extracting content with LLM\")\n",
    "\n",
    "    # Grab the first 1000 tokens of the site\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000, chunk_overlap=0\n",
    "    )\n",
    "    splits = splitter.split_documents(docs_transformed)\n",
    "\n",
    "    # Process the first split\n",
    "    extracted_content = extract(schema=schema, content=splits[0].page_content)\n",
    "    pprint.pprint(extracted_content)\n",
    "    return extracted_content\n",
    "\n",
    "\n",
    "urls = [\"https://www.wsj.com\"]\n",
    "extracted_content = scrape_with_playwright(urls, schema=schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
